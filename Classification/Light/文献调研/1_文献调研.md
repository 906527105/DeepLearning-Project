# <center>图像增强论文调研</center>







## Abstract  

低光下的图像部分能用传统的方法解决，例如直方图均衡得到很好的效果。虽然这些方法产生了有希望的输出，但每个过程的运行时间可能很长。 通过深度学习，网络经过培训（需要很长时间）并生成一个过滤器，不仅能产生更好的效果，也能够将训练好的网络用来智能手机上。

[TOC]







## Article



- **STN**:  Spatial Transformer Networks


- **Deformable** Convolutional Networks


- **ACNet**: Strengthening the Kernel Skeletons for Powerful CNN via Asymmetric Convolution Blocks



- Cross-Domain Few-Shot Classification via Learned Feature-Wise Transformation (ICLR 2020 spotlight) [[github]](https://github.com/hytseng0509/CrossDomainFewShot) 


- Deforming kernels to adapt towards object deformation. To appear in ICLR 2020.  
针对形变目标的defromable kernel获得Effiictive receptive field





### 1. low-light image enhancement



#### 1.1 Traditional methods  

- Maini R, Aggarwal H. A Comprehensive Review of Image Enhancement Techniques[J]. Computer Science, 2010.



#### 1.2 Learning based methods  





|                             论文                             |                    数据集                    |    网络参数    | 实验结果 |                      文章名称&项目地址                       |
| :----------------------------------------------------------: | :------------------------------------------: | :------------: | :------: | :----------------------------------------------------------: |
|                   Learning to see in dark                    |  数据集由作者自己设计拍摄，在项目中可以获取  |      FCN       |          | (2018CVPR)Learning to See in the Dark<br />[[TF >1.1]](https://github.com/cchen156/Learning-to-See-in-the-Dark) |
| Learning a Deep single <br />image Contrast Enhancement <br />from Multi-Exposure Image |    数据集由作者自己收集，在项目中可以获取    |      CNN       |          | (2018 TIP)Learning a Deep Single Image Contrast Enhancer from Multi-Exposure Images <br /> [[Caffe\]](https://github.com/csjcai/SICE) |
| Deep Bilateral Learning for<br />real-time image enhancement(Google) |    数据集由作者自己收集，在项目中可以获取    |      CNN       |          | (2017 SIGGRAPH)Deep Bilateral Learning for Real-Time Image Enhancement<br />[[TF1.1]](https://github.com/google/hdrnet/blob/master/hdrnet/requirements.txt) |
|                            MBLLEN                            |              PASCAL VOC dataset              |      CNN       |          | (2018 BMVC) MBLLEN: Low-light Image/Video Enhancement Using CNNs<br />[[TF 1.6]](https://github.com/Lvfeifan/MBLLEN) |
|                          LightenNet                          | 从互联网上下载照片，然后降低光度作为训练数据 |      CNN       |          | (2018 PR)LightenNet: A Convolutional Neural Network for weakly illuminated image enhancement<br />[[paper]](https://li-chongyi.github.io/proj_lowlight.html)  [[matlab]](https://li-chongyi.github.io/proj_lowlight.html) |
|                            LL-Net                            |     http://decsai.ugr.es/cvg/dbimagenes/     | 深度自动编码器 |          | (2015 PR)LLNet: A Deep Autoencoder approach to Natural Low-light Image Enhancement  <br />[[paper]](https://arxiv.org/pdf/1511.03995.pdf)  [[theano]](https://github.com/kglore/llnet_color) |









- (2019 ACMMM) Kindling the Darkness: a Practical Low-light Image Enhancer.

  [[TF > 1.1]](https://github.com/zhangyhuaee/KinD)  

  干货挺多，据称是state-of-the-art。它提出了低光照增强任务存在的三个难点：

  （1） 如何有效的从单张图像中估计出光照图成分，并且可以灵活调整光照level?

  （2） 在提升图像亮度后，如何移除诸如噪声和颜色失真之类的退化？

  （3） 在没有ground-truth的情况下，样本数目有限的情况下，如何训练模型？

  这篇文章的增强思路还是沿用了Retinex-Net的decomposition->enhance的两阶段方式，网络总共分为三个模块：Decomposition-Net、Restoration-Net和Adjustment-Net，分别执行图像分解、反射图恢复、光照图调整。一些创新点如下：

  （a）对于Decomposition-Net，其损失函数除了沿用Retinex-Net的重构损失和反射图一致损失外，针对光照图的区域平滑性和相互一致性，还增加了两个新的损失函数。

  （b）对于Restoration-Net，考虑到了低光照情况下反射图往往存在着退化效应，因此使用了良好光照情况下的反射图作为参考。反射图中的退化效应的分布很复杂，高度依赖于光照分布，因此引入光照图信息。

  （c）对于Adjustment-Net，实现了一个能够连续调节光照强度的机制（将增强比率作为特征图和光照图合并后作为输入）。通过和伽马校正进行对比，证明它们的调节方法更符合实际情况。



- (2019 Arxiv) EnlightenGAN: Deep Light Enhancement without Paired Supervision
  [[Torch==0.3]](https://github.com/TAMU-VITA/EnlightenGAN)  
  
  
  
- (2019 CVPR ) Underexposed Photo Enhancement Using Deep Illumination Estimation
  https://github.com/wangruixing/DeepUPE
  
- (2018 CVPR ) **Learning to See in the Dark**
  https://github.com/cchen156/Learning-to-See-in-the-Dark  
  
  暗光照条件下的图像增强算法有很多，比如直方图均衡，同态滤波，BM3D降噪，HDR Net等等。这些方法都存在各自的弱点，比如只解决单一问题，金标准都来自于仿真数据，无法适用于极端自然场景等等。针对这一系列的问题，这篇文章主要做了两个方面的工作来实现暗光照条件下图像的增强。一是建立了一个自然场景下的数据集；二是利用这个数据集训练了一个FCN网络。  
  
  这篇文章的作者他们是怎么建立数据集的:    
  
  首先，明确自己的目的：自然场景、极端低光照。那么，这个数据集不能用仿真数据，必须实地采集。同时，也需要包含室内室外。最后，为了和其他算法（比如burst denoising，需要多帧低光照图像）做对比，对同一个场景同一个拍摄角度会采集多帧图像。
  
  建立的数据集信息如下：  
  
  <img src="https://ftp.bmp.ovh/imgs/2020/02/83d75e34d7098652.png" style="zoom:50%;" />
  
  **FCN网络**
  
  有了数据集，接下来就是训练网络了。这篇文章中的pipeline如下图  
  
  <img src="https://ftp.bmp.ovh/imgs/2020/02/bd57f34715624929.png" style="zoom:67%;" />
  
  对于输入的raw数据，先打包成4个通道，然后对每个通道做一次2两倍的下采样。然后将放大因子作为一个输入，送进网络（这里的放大因子指的是输入图片和金标准之间曝光时间的倍数）。输出是一个12通道的feature map，最后转化为sRGB图像。
  
  主体的网络结构选择了CAN（快速图像处理的多尺度上下文聚合网络）和U-NET，后续有对比这两种主题网络结构的区别。  
  
  不同的放大倍数，网络输出的图片亮度也差别很大。下面是一个实例图片。   
  
  ![](https://ftp.bmp.ovh/imgs/2020/02/516f8c17354a6cc5.png)
  
  评价指标采用的是第三方盲选:  
  
  ![](https://ftp.bmp.ovh/imgs/2020/02/4c4d7fa7a8086988.png)
  
  还有一个采用PSNR（峰值信噪比）和SSIM（结构相似性）作为评价指标的表格:  
  
  ![](https://ftp.bmp.ovh/imgs/2020/02/57057b0f41154e42.png)
  
  **总结**
  
  总体来说，这篇文章建立了这样一个数据集，以及基于这个数据集训练的模型还是很有意义的。之后，其他研究者和从业者，也可以拿这个数据集做很多其他的研究。
  
  但也正如作者在文章里说的，他们的方法中没有加入色调映射，数据集里也没有采集人和动态的图片。另外呢，放大因子也需要手动输入，没有实现自动化。同时，算法不够实时，不能用于移动端。这些都是未来可以改进的地方。
  
- (2018 BMVC ) **MBLLEN**: Low-light Image/Video Enhancement Using CNNs

  本文提出了一种新的基于CNN的低光增强方法。 现有方法通常依赖于某些假设，并且经常忽略诸如图像之类的其他因素噪声。 为了解决这些挑战，我们的目标是培训一个强大而灵活的网络，以更有效地解决这一任务。 我们的网络由三个模块组成，即FEM，EM和FM。 它被设计为能够从FEM中的不同层提取丰富的特征，并通过EM中的不同子网来增强它们。 通过FM融合多分支输出，它可以产生高质量的结果，并且大大超过了现有技术水平。 还可以修改网络以有效处理弱光视频。

  ![](https://pic2.zhimg.com/80/v2-a196e0a0f61dfe1484dd1342fe88a99d_hd.jpg)  

  与其他的网络对比效果：  

  ![](https://pic2.zhimg.com/80/v2-1df7098b7402977fc545a1970a3a489d_hd.jpg)  

  

- (2018 BMVC) Deep **Retinex Decomposition** for Low-Light Enhancement
  [[TF >=1.5]](https://github.com/weichen582/RetinexNet)  
  
  受Retinex理论的启发，它采用了两阶段式的先分解后增强的步骤，完全采用CNN实现。对于Decom-Net的训练，引入了反射图一致性约束（consistency of reflectance）和光照图平滑性约束（smoothness of illumination），非常容易复现，实验效果也不错。  
  
  主要贡献如下：
  
  （1）构建了paired的低光照/正常光照数据集LOL dataset，应该也是第一个在真实场景下采集的paired dataset.该数据集分为两部分：真实场景的图像数据是通过改变相机感光度和曝光时间得到的；合成的图像数据是用Adobe Lightroom接口调节得到的，并且调节后图像的Y通道直方图必须尽可能地接近真实低光照场景。
  
  （2）提出了Retinex-Net，它分为两个子网络：Decom-Net能够对图像进行解耦，得到光照图和反射图；Enhance-Net对前面得到的光照图进行增强，增强后的光照图和原来的反射图相乘就得到了增强结果。另外，考虑到噪声问题，采用一种联合去噪和增强的策略，去噪方法采用BM3D。
  
  （3）提出一个structure-aware total variation constraint，就是用反射图梯度作为权值对TV loss进行加权，从而在保证平滑约束的同时不破坏纹理细节和边界信息。  
  
  ![](https://ftp.bmp.ovh/imgs/2020/02/f74a9f631f5676f8.png)
  
- (2018 Pattern Recognition Letters) **LightenNet:** A Convolutional Neural Network for weakly illuminated image enhancement
  https://github.com/Li-Chongyi/Low-Light-Codes
  
  现在的方法在增强 弱照明 度的图像时显示出局限性，表现在不同的光照条件下，（这里变化的照明条件包括了非均匀照明，背光照明，极弱的照明强度，光线充足等下）。本文使用了弱照明图像增强的可训练卷积神经网络（CNN），即LightenNet，它将弱照明图像作为输入并输出其照明图随后用于获得基于Retinex模型的增强图像。所提出的方法产生视觉上令人愉悦的结果，而没有过度或欠增强的区域。
  
  LightenNet的核心思想是采用以下这个相片模型：
  
  ![](https://pic1.zhimg.com/80/v2-b1ca6016a76eea68fd2af6907f19f444_hd.jpg)
  
  首先建立一个相片的模型，我们假设一张 微光图像 = 正常图像 *一个光照映射。
  
  所以我们要恢复出原来的图像就是找到这个光照映射，然后将它移除掉就是正常的图像了。
  
  所以，为了得到这个映射，本文作者首先从互联网上收集了大量的光照良好的图片，然后对这些光照良好的图片进行处理得到低光下的照片，这样就能确定深度网络中图片的输入与输出了，接下来只要学习这个模型的参数就可以了。
  
  ![](https://pic4.zhimg.com/80/v2-675d54b5b05dfcd40a0f3aef5eec51bf_hd.jpg) 
  
  本文提出的方法是尽力在Retinex 的模型上，该模型能够估计其光照映射来增强图像，训练后的LightenNet模型的效果如下：
  
  可以看到相比于其他图像方法，这个方法具有更好的视觉效果。
  
  ![](https://pic1.zhimg.com/80/v2-144394b4061c5a37583f8462f8b43b04_hd.jpg) 
  
  局限：该方法在在噪声比较大的低光图像下，会引起图像的块效应。
  
  

- 2015 **LLNet:** A Deep Autoencoder Approach to Natural Low-light Image Enhancement

  这是第一个使用深度学习解决图像增强的论文。（16年8月发表的）

  本文使用深度自动编码器（我们称之为 低光網絡，LLNet）从表示学习的角度来解决低光图像增强的问题，这些自动编码器经过训练以学习低光图像中的基础信号特征并自适应地增亮和去噪。

  ![](https://pic4.zhimg.com/80/v2-a5d422e70a7517283cf22974aae0a177_hd.jpg)

  训练的思路与一般的神经网络的训练方法都一样，都是与打标签的图像做对比求误差，然后进行反向传播

  ![](https://pic3.zhimg.com/80/v2-9cc5686ab2cad1b9edf86563528663a6_hd.jpg)

  效果对比，使用这种方法与传统的方法作对比  

  ![](https://pic1.zhimg.com/80/v2-af5c12c2159b81fff4bc551fa02b0120_hd.jpg)
  结论：该能够适用于不同程度的自然低光图像增强问题。





### 2. 自动色阶  

作用：自动调整图像中的黑白场。

原理：剪切每个通道中的阴影和高光部分，并将每个颜色通道中最亮或最暗的像素映射到纯白或纯黑；中间像素按比例重新分配分布。

运用：会增强图像中的对比度，因数像素值会增大。

特点：单独调整每个颜色通道，有可能会移去颜色或引入色痕。在像素平衡分布且需要以简单方式增加对比度的特定图像中，提供较好的效果





### 3. 自动对比度

作用：自动调整图像的对比度。

原理：剪切图像中的阴影和高光值，再将图像中的剩余部分的最亮和最暗像素映射到纯白或纯黑；中间像素按比例重新分配分布。

效果：会使高光看上去更亮，阴影看上去更暗。

特点：不会单独调整各个颜色通道，不会引入或消除色痕。

默认值情况：剪切白色/黑色像素的0.5%；也就是说忽略两个极端像素的0.5%

（可使用【色阶】或【曲线】对话框中的“自动颜色校正”选项来更改这个默认设置）

运用：可改进许多摄影或连续色调图像的外观，但无法改变单调颜色的图像属性。



### 4. 自动颜色   

原理：能过搜索图像来标识阴影、中间调、高光，从而校正图像的对比度和颜色。

默认值情况：使用“RGB128灰色（中度灰色）”这一目标颜色来中和中间调，并将阴影和高光剪切0.5%

（可使用【色阶】或【曲线】对话框中的“自动颜色校正”选项来更改这个默认设置）



### 5.  自动色彩均衡  

- (IPOL 2012) Automatic Color Enhancement (ACE) and its Fast Implementation
  http://demo.ipol.im/demo/g_ace/

自动色彩均衡：https://www.cnblogs.com/wangyong/p/9119394.html

自动色彩均衡（ACE）快速算法：https://blog.csdn.net/zmshy2128/article/details/53470357



### 6. 自动白平衡化   

https://blog.csdn.net/weixin_43379058/article/details/88606961

(ISCS 2005) A Novel Automatic White Balance Method For Digital Still Cameras



### 7. 直方图均衡化  

直方图均衡化是图像处理领域中利用图像直方图对对比度进行调整的方法。

https://docs.opencv.org/2.4/modules/imgproc/doc/histograms.html?highlight=equalizehist



### 8. 拉普拉斯算子  

使用中心为5的8邻域拉普拉斯算子与图像卷积可以达到锐化增强图像的目的

https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html#filter2d



### 9. 对数log变换  

对数变换可以将图像的低灰度值部分扩展，显示出低灰度部分更多的细节，将其高灰度值部分压缩，减少高灰度值部分的细节，从而达到强调图像低灰度部分的目的。



### 10. 伽马变换

伽马变换主要用于图像的校正，将灰度过高或者灰度过低的图片进行修正，增强对比度。



### 11. 指数图像  

指数变换的作用是扩展图像的高灰度级、压缩低灰度级，可用于亮度过高的图像。



### 12.  曝光过度问题处理  

对于曝光过度问题，可以通过计算当前图像的反相（255-image)，然后取当前图像和反相图像的较小者为当前像素位置的值。

### 13. 高反差保留  

将图像中颜色、明暗反差较大两部分的交界处保留下来。高反差保留 = 原图 - 高斯模糊图

https://docs.opencv.org/2.4/modules/imgproc/doc/filtering.html?highlight=gaussianblur#gaussianblur



### 14. 偏色  

- (CVPR 2019) When Color Constancy Goes Wrong: Correcting Improperly White-Balanced Images
  http://130.63.97.192/WB_for_srgb_rendered_images/demo.html
  效果不佳
- (CVPR 2019) Quasi-Unsupervised Color Constancy
  https://github.com/claudio-unipv/quasi-unsupervised-cc
  效果一般
- (CVPR 2018) Improving Color Reproduction Accuracy on Cameras
  https://karaimer.github.io/camera-color/
  Matlab 代码
- (SIGGRAPH 2018) Exposure: A White-Box Photo Post-Processing Framework
  https://github.com/yuanming-hu/exposure
  效果偏暗
- (CVPR 2017) Fast Fourier Color Constancy
  https://github.com/google/ffcc
  Matlab Toolbox
- (CVPR 2017) FC4: Fully Convolutional Color Constancy with Confidence-weighted Pooling
  https://github.com/yuanming-hu/fc4
  论文 Exposure 一作的旧工作



### 15. 高动态图像增强  

从双边滤波到 HDRNet https://zhuanlan.zhihu.com/p/37404280

- (CVPR 2018 spotlight) Deep Photo Enhancer: Unpaired Learning for Image Enhancement from Photographs with GANs
  https://github.com/nothinglo/Deep-Photo-Enhancer
- (SIGGRAPH 2017) Deep Bilateral Learning for Real-Time Image Enhancement
  https://groups.csail.mit.edu/graphics/hdrnet/



### 16. 颜色滤镜  

颜色滤镜即调色滤镜，也是最常见的滤镜，任何通过调节图像像素值的亮度、对比度、饱和度、色相等等方法，得到的不同于原图像颜色的效果，都统称为颜色滤镜。

LUT是Look Up Table的缩写，俗称为颜色查找表。颜色查找表有1D LUT、2D LUT、3D LUT三种。

https://blog.csdn.net/trent1985/article/details/81101688





## Summarize







## Reference  

- 图像增强 Image Enhancement [[blog]](https://lijiancheng0614.github.io/2019/07/21/2019_07_21_Image_Enhancement/)  

- 图像质量评估 Image Quality Assessment [[blog]](https://lijiancheng0614.github.io/2019/07/30/2019_07_30_Image_Quality_Assessment/) 

- 基于深度学习的图像增强评估 [[zhihu]](https://zhuanlan.zhihu.com/p/63218165)

- 基于深度学习的低光图像增强方法总结 [[zhihu]](https://zhuanlan.zhihu.com/p/78297097) 

- Data Augmentation in Deep Learning [[url]](https://imbinwang.github.io/research/data-augmentation-in-deep-learning)   

- paper with code image enhancement [[url]](https://paperswithcode.com/task/image-enhancement/latest)

- A review on image enhancement with deepleaning approch [[paper]](https://www.accentsjournals.org/PaperDirectory/Journal/TIPCV/2018/5/1.pdf)

- google scholar image enhancement [[url]](https://scholar.google.com/scholar?q=Image+Enhancement+deep+learning&hl=en&as_sdt=0&as_vis=1&oi=scholart)

- Learn to see in the dark [[中文笔记]](https://zhuanlan.zhihu.com/p/54119008)     

